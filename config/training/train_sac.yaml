results_dir: results
episode_budget: 100_000
eval_check_interval: 100
save_interval: 100

SelfPlay:
  self_play_period: 1000  # epochs
  opponent: weak  # weak, strong, self_play
  Env:
    keep_mode: true
    mode: NORMAL
    verbose: false
  WarmupSchedule:
    n_episodes_weak: 5
    n_episodes_strong: 5

SAC:
  lr_pi: 0.0005
  lr_q: 0.001
  init_alpha: 0.01
  gamma: 0.98
  batch_size: 32
  buffer_limit: 50000
  start_buffer_size: 1000
  train_iterations: 20
  tau: 0.01  # for target network soft update
  target_entropy: -1.0  # for automated alpha update
  lr_alpha: 0.001  # for automated alpha update
  action_magnitude: 1
  actor_config:
    architecture: [128, 128]
    activation_function: ReLU
    latent_dim: 128
